{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "quantization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANTdswAEMDpi"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import copy\n",
        "import random\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.quantization import QuantStub, DeQuantStub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBTJusGIoi17"
      },
      "source": [
        "# Статическая квантизация\n",
        "Статическая квантизация позволяет сразу все операции перевести в int, без необходимости дополнительно что-то расчитывать в процессе предсказания.\n",
        "\n",
        "По сравнению с моделью из главы про разряжение нейронной сети, архитектура повлекла небольшие изменения. В частности так как квантизация не происходит динамически, необходимо дополнительно руками квантовать входные данные и деквантовать ответ. Это можно видеть в `forward` методе. \n",
        "\n",
        "Также стоит обратить внимание на применение ` nn.quantized.FloatFunctional()` при выполнении skip connection в ResNet архитектуре. Это необходимо для правильного выполнения операции сложения со сквантованным входом и весами в представлении float32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHT-HFLVq6_g"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCH = 6\n",
        "DEVICE = 'cuda'\n",
        "SEED = 5\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLACzjbNMIea"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, quant_func, dequant_func, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.skip_add = nn.quantized.FloatFunctional()\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "        self.quant = quant_func\n",
        "        self.dequant = dequant_func\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        skip_branch = self.shortcut(x)\n",
        "        out = self.skip_add.add(out, skip_branch)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        block = BasicBlock\n",
        "        num_blocks = [2, 2, 2, 2]\n",
        "        self.in_planes = 64\n",
        "        self.quant = QuantStub()\n",
        "        self.dequant = DeQuantStub()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=1)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, self.quant, self.dequant, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        out = self.dequant(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MUD5dczMNee"
      },
      "source": [
        "def fit(model, train_loader, epoch_number=5, device='cuda'):\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    error = nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "    \n",
        "    for epoch in range(epoch_number):\n",
        "        correct = 0\n",
        "        \n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
        "            var_X_batch = X_batch.to(device)\n",
        "            var_y_batch = y_batch.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output = model(var_X_batch)\n",
        "            loss = error(output, var_y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            predicted = torch.max(output.data, 1)[1] \n",
        "            correct += (predicted == var_y_batch).sum()\n",
        "            if batch_idx % 500 == 0:\n",
        "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
        "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), \n",
        "                    100.*batch_idx / len(train_loader), loss.data, \n",
        "                    float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))\n",
        "                \n",
        "                \n",
        "def evaluate(model, loader, device='cuda'):\n",
        "    correct = 0\n",
        "    model.eval() \n",
        "    for test_imgs, test_labels in loader:\n",
        "        test_imgs = test_imgs.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "        \n",
        "        output = model(test_imgs)\n",
        "        predicted = torch.max(output,1)[1]\n",
        "        correct += (predicted == test_labels).sum()\n",
        "    print(\"Test accuracy:{:.3f}% \".format( float(correct) / (len(loader)*BATCH_SIZE)))\n",
        "\n",
        "    \n",
        "def calc_size(model):\n",
        "    torch.save(model.state_dict(), \"/tmp/model.p\")\n",
        "    size=os.path.getsize(\"/tmp/model.p\")\n",
        "    os.remove('/tmp/model.p')\n",
        "    return \"{:.3f} KB\".format(size / 1024)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-LyxLfeoVf8"
      },
      "source": [
        "Подготовим данные для обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRFtdc69NlE1"
      },
      "source": [
        "train_data = torchvision.datasets.FashionMNIST('./', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "test_data = torchvision.datasets.FashionMNIST('./', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size = BATCH_SIZE, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJJMtOXjna_Y"
      },
      "source": [
        "Статическое квантование после обучения включает в себя не только преобразование весов из float32 в int, как при динамическом квантовании, но также выполнение дополнительного шага первоначальной прогонки выборки обучающих данных через сеть и вычисления результирующих распределений различных активаций (в частности, это выполняется путем вставки модулей, так называемого наблюдателя, в нужные места после каждой операции, которые записывают эти данные). Эти распределения затем используются для определения того, как конкретно различные активации должны быть сквантованы во время вывода (вычисляется свой коэффициент масштабирования и смещения). Важно отметить, что этот дополнительный шаг позволяет нам передавать квантованные значения между операциями вместо преобразования этих значений в числа с плавающей запятой - а затем обратно в целые числа - между каждой операцией, что приводит к значительному ускорению."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nXFKEA7ObAA",
        "outputId": "17afb9bc-56fd-4577-8772-f4ebd5edfc61"
      },
      "source": [
        "resnet = ResNet()\n",
        "resnet.to(DEVICE)\n",
        "torch.manual_seed(SEED)\n",
        "fit(resnet, train_loader, epoch_number=EPOCH, device=DEVICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0 [0/60000 (0%)]\tLoss: 2.333537\t Accuracy:9.375%\n",
            "Epoch : 0 [16000/60000 (27%)]\tLoss: 0.385268\t Accuracy:74.613%\n",
            "Epoch : 0 [32000/60000 (53%)]\tLoss: 0.373411\t Accuracy:79.661%\n",
            "Epoch : 0 [48000/60000 (80%)]\tLoss: 0.338566\t Accuracy:82.535%\n",
            "Epoch : 1 [0/60000 (0%)]\tLoss: 0.168826\t Accuracy:96.875%\n",
            "Epoch : 1 [16000/60000 (27%)]\tLoss: 0.335091\t Accuracy:90.151%\n",
            "Epoch : 1 [32000/60000 (53%)]\tLoss: 0.074745\t Accuracy:90.207%\n",
            "Epoch : 1 [48000/60000 (80%)]\tLoss: 0.176288\t Accuracy:90.408%\n",
            "Epoch : 2 [0/60000 (0%)]\tLoss: 0.195265\t Accuracy:90.625%\n",
            "Epoch : 2 [16000/60000 (27%)]\tLoss: 0.140607\t Accuracy:91.935%\n",
            "Epoch : 2 [32000/60000 (53%)]\tLoss: 0.321993\t Accuracy:91.868%\n",
            "Epoch : 2 [48000/60000 (80%)]\tLoss: 0.064194\t Accuracy:91.920%\n",
            "Epoch : 3 [0/60000 (0%)]\tLoss: 0.210873\t Accuracy:90.625%\n",
            "Epoch : 3 [16000/60000 (27%)]\tLoss: 0.084497\t Accuracy:93.569%\n",
            "Epoch : 3 [32000/60000 (53%)]\tLoss: 0.244260\t Accuracy:93.300%\n",
            "Epoch : 3 [48000/60000 (80%)]\tLoss: 0.294583\t Accuracy:93.269%\n",
            "Epoch : 4 [0/60000 (0%)]\tLoss: 0.071800\t Accuracy:96.875%\n",
            "Epoch : 4 [16000/60000 (27%)]\tLoss: 0.111418\t Accuracy:94.667%\n",
            "Epoch : 4 [32000/60000 (53%)]\tLoss: 0.168507\t Accuracy:94.552%\n",
            "Epoch : 4 [48000/60000 (80%)]\tLoss: 0.093643\t Accuracy:94.412%\n",
            "Epoch : 5 [0/60000 (0%)]\tLoss: 0.194862\t Accuracy:87.500%\n",
            "Epoch : 5 [16000/60000 (27%)]\tLoss: 0.124385\t Accuracy:95.659%\n",
            "Epoch : 5 [32000/60000 (53%)]\tLoss: 0.057616\t Accuracy:95.411%\n",
            "Epoch : 5 [48000/60000 (80%)]\tLoss: 0.347179\t Accuracy:95.378%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8_FURPTrKHk"
      },
      "source": [
        "Мы Натренировали изначальную сеть на данных FashionMNIST, теперь изерим качество. Это будет нашим бейзлайном."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpz_Oto9PoDz",
        "outputId": "35e18431-de44-4bb2-c58b-faec545decff"
      },
      "source": [
        "evaluate(resnet, test_loader, device=DEVICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:0.925% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOE5tDtVre_T"
      },
      "source": [
        "Полученное качество составляет 92.5% на валидационной выборке. Далее замерим время инференса сети на ЦПУ. Чтобы замер был честный, отключим возможность PyTorch использовать несколько потоков и будем использовать всего один поток вычислений\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZOgKTc7W4wJ"
      },
      "source": [
        "from contextlib import contextmanager\n",
        "\n",
        "@contextmanager\n",
        "def single_thread():  \n",
        "    num = torch.get_num_threads()\n",
        "    torch.set_num_threads(1)\n",
        "    yield\n",
        "    torch.set_num_threads(num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGRYaP5kXcGZ",
        "outputId": "926a7df2-c16e-457e-c503-68b21042066a"
      },
      "source": [
        "%%timeit -r5\n",
        "resnet.to('cpu')\n",
        "with single_thread():\n",
        "    evaluate(resnet, test_loader, device='cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:0.925% \n",
            "Test accuracy:0.925% \n",
            "Test accuracy:0.925% \n",
            "Test accuracy:0.925% \n",
            "Test accuracy:0.925% \n",
            "Test accuracy:0.925% \n",
            "1 loop, best of 5: 6min 31s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py49wyfBr6cb"
      },
      "source": [
        "Видим, что скорость инференса сети в среднем 6 минут и 31 секунда. Измерим вес сети, занимаемой памяти в хранилище данных. Она составляет примерно 44 мб памяти. Теперь применим алгоритмы квантизации и попробуем уменьшить это значение в несколько раз, при этом не потеряв сильно в качестве."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "t3u88W_Sbi2w",
        "outputId": "c8322f2a-48be-4302-e237-27ef1666bada"
      },
      "source": [
        "calc_size(resnet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'43722.743 KB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCloTkB5m0_U"
      },
      "source": [
        "Для моделей мы также можем указать конфиг квантования, где в частности можно указать библиотеку для работы с квантованными значениями. Далее устанавливаем модули подсчета параметров квантования. По умолчанию исползуется HistogramObserver, это модуль, который рассчтывает параметры на основе гистрограммы распределения значнеий для конкретного слоя"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlZUDSE0XgnS"
      },
      "source": [
        "resnet.qconfig = torch.quantization.get_default_qconfig('fbgemm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmzfGU78YI-h",
        "outputId": "3587389b-7a4e-42e9-f8a9-73ecc788a587"
      },
      "source": [
        "torch.quantization.prepare(resnet, inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:123: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): HistogramObserver()\n",
              "  )\n",
              "  (dequant): DeQuantStub()\n",
              "  (conv1): Conv2d(\n",
              "    1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (activation_post_process): HistogramObserver()\n",
              "  )\n",
              "  (bn1): BatchNorm2d(\n",
              "    64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "    (activation_post_process): HistogramObserver()\n",
              "  )\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(\n",
              "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn1): BatchNorm2d(\n",
              "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (conv2): Conv2d(\n",
              "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(\n",
              "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (quant): QuantStub(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (dequant): DeQuantStub()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(\n",
              "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn1): BatchNorm2d(\n",
              "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (conv2): Conv2d(\n",
              "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(\n",
              "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (quant): QuantStub(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (dequant): DeQuantStub()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(\n",
              "        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn1): BatchNorm2d(\n",
              "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (conv2): Conv2d(\n",
              "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(\n",
              "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(\n",
              "          64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (activation_post_process): HistogramObserver()\n",
              "        )\n",
              "        (1): BatchNorm2d(\n",
              "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (activation_post_process): HistogramObserver()\n",
              "        )\n",
              "      )\n",
              "      (quant): QuantStub(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (dequant): DeQuantStub()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(\n",
              "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn1): BatchNorm2d(\n",
              "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (conv2): Conv2d(\n",
              "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(\n",
              "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (quant): QuantStub(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (dequant): DeQuantStub()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(\n",
              "        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn1): BatchNorm2d(\n",
              "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (conv2): Conv2d(\n",
              "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(\n",
              "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(\n",
              "          128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
              "          (activation_post_process): HistogramObserver()\n",
              "        )\n",
              "        (1): BatchNorm2d(\n",
              "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (activation_post_process): HistogramObserver()\n",
              "        )\n",
              "      )\n",
              "      (quant): QuantStub(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (dequant): DeQuantStub()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(\n",
              "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn1): BatchNorm2d(\n",
              "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (conv2): Conv2d(\n",
              "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(\n",
              "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (quant): QuantStub(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (dequant): DeQuantStub()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(\n",
              "        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn1): BatchNorm2d(\n",
              "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (conv2): Conv2d(\n",
              "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(\n",
              "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(\n",
              "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
              "          (activation_post_process): HistogramObserver()\n",
              "        )\n",
              "        (1): BatchNorm2d(\n",
              "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (activation_post_process): HistogramObserver()\n",
              "        )\n",
              "      )\n",
              "      (quant): QuantStub(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (dequant): DeQuantStub()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(\n",
              "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn1): BatchNorm2d(\n",
              "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (conv2): Conv2d(\n",
              "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(\n",
              "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (quant): QuantStub(\n",
              "        (activation_post_process): HistogramObserver()\n",
              "      )\n",
              "      (dequant): DeQuantStub()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(\n",
              "    in_features=512, out_features=10, bias=True\n",
              "    (activation_post_process): HistogramObserver()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n12DMfFdmp5e"
      },
      "source": [
        "Прогоняем всю обучающую выборку через сеть.\n",
        "Само значение нам не интересно, нам важно, чтобы посчитались параметры"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXwnW7yoYXYz",
        "outputId": "e67d8c99-ef83-44ae-f1f2-15d14d198641"
      },
      "source": [
        "resnet.to(DEVICE)\n",
        "evaluate(resnet, train_loader, device=DEVICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:0.968% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVUlT4Msmmqf"
      },
      "source": [
        "Фиксируем полученные веса и параметры квантизации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbQ3WRMiYhEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89cdfb1f-9c4e-486f-8f50-0a3abf55f89e"
      },
      "source": [
        "resnet.cpu()\n",
        "torch.quantization.convert(resnet, inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "  (dequant): DeQuantize()\n",
              "  (conv1): QuantizedConv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.02345956489443779, zero_point=63, padding=(1, 1), bias=False)\n",
              "  (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.4392222762107849, zero_point=76, padding=(1, 1), bias=False)\n",
              "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.33188363909721375, zero_point=74, padding=(1, 1), bias=False)\n",
              "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (skip_add): QFunctional(\n",
              "        scale=0.15338747203350067, zero_point=52\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "      (dequant): DeQuantize()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.6362550854682922, zero_point=70, padding=(1, 1), bias=False)\n",
              "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.45390498638153076, zero_point=72, padding=(1, 1), bias=False)\n",
              "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (skip_add): QFunctional(\n",
              "        scale=0.16316750645637512, zero_point=44\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "      (dequant): DeQuantize()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.7654872536659241, zero_point=77, padding=(1, 1), bias=False)\n",
              "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.6774553656578064, zero_point=68, padding=(1, 1), bias=False)\n",
              "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (skip_add): QFunctional(\n",
              "        scale=0.18550744652748108, zero_point=61\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.22077229619026184, zero_point=64, bias=False)\n",
              "        (1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "      (dequant): DeQuantize()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.5618809461593628, zero_point=66, padding=(1, 1), bias=False)\n",
              "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.1443912982940674, zero_point=68, padding=(1, 1), bias=False)\n",
              "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (skip_add): QFunctional(\n",
              "        scale=0.15772882103919983, zero_point=40\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "      (dequant): DeQuantize()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=1.5855485200881958, zero_point=69, padding=(1, 1), bias=False)\n",
              "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.041472315788269, zero_point=70, padding=(1, 1), bias=False)\n",
              "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (skip_add): QFunctional(\n",
              "        scale=0.1618388295173645, zero_point=58\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.4152944087982178, zero_point=64, bias=False)\n",
              "        (1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "      (dequant): DeQuantize()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.7836670875549316, zero_point=68, padding=(1, 1), bias=False)\n",
              "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.7543346881866455, zero_point=72, padding=(1, 1), bias=False)\n",
              "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (skip_add): QFunctional(\n",
              "        scale=0.16100019216537476, zero_point=45\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "      (dequant): DeQuantize()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=2.042210340499878, zero_point=61, padding=(1, 1), bias=False)\n",
              "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.1820474863052368, zero_point=68, padding=(1, 1), bias=False)\n",
              "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (skip_add): QFunctional(\n",
              "        scale=0.1334652304649353, zero_point=64\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.5494555234909058, zero_point=64, bias=False)\n",
              "        (1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "      (dequant): DeQuantize()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.6312438249588013, zero_point=65, padding=(1, 1), bias=False)\n",
              "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.501786708831787, zero_point=58, padding=(1, 1), bias=False)\n",
              "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (skip_add): QFunctional(\n",
              "        scale=0.13579115271568298, zero_point=49\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "      (dequant): DeQuantize()\n",
              "    )\n",
              "  )\n",
              "  (linear): QuantizedLinear(in_features=512, out_features=10, scale=0.3220852315425873, zero_point=65, qscheme=torch.per_channel_affine)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x900cDK7mKfr"
      },
      "source": [
        "Посчитаем теперь размер нашей сети. Применяя алгоритм квантизации, удалось сжать ее размер примерно в 4 раза. Теперь вместо  44 мб. она занимает всего 11 мб."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juqEi0i4b4qi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d5f1aef4-2464-44a5-90a2-2caaa2e945ba"
      },
      "source": [
        "calc_size(resnet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'11128.655 KB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No0oOR0Rl_eQ"
      },
      "source": [
        "Можно видеть, что теперь все веса имеют свой коэффициент масштабирования и смещения, а также увидеть int8 представление на примере линейного слоя"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhQ0mU4tb7Kj",
        "outputId": "bb483cbc-fbf3-4dc5-eaf3-a0c714661f72"
      },
      "source": [
        "print(resnet.conv1.weight)\n",
        "resnet.linear.weight().int_repr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Conv2d.weight of QuantizedConv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.02345956489443779, zero_point=63, padding=(1, 1), bias=False)>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   4,   -5,   -5,  ...,   48,  -13,  -16],\n",
              "        [ -78,   -4,   -9,  ...,   37,  -29,    3],\n",
              "        [ -58,  -30,  -95,  ..., -127,  -14,   20],\n",
              "        ...,\n",
              "        [   7,   15,   12,  ...,   15,  -17,  -13],\n",
              "        [ -28,  -79,   25,  ...,  -43,   70,   18],\n",
              "        [ -36,   20,   15,  ...,  -50,    9,    3]], dtype=torch.int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X6TxHZ3lLnx"
      },
      "source": [
        "По результатам тестирования можно сделать вывод, что просадки в точности сети нет, покрайней мере на наших тестовых данных удалось достичь метрики оригинальной модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIizxLTRcB2v",
        "outputId": "7b8bcc8f-41cf-48dc-e67a-5e936315bb26"
      },
      "source": [
        "resnet.to('cpu')\n",
        "evaluate(resnet, test_loader, device='cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:0.925% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7E8TfgolE9j"
      },
      "source": [
        "Интересно сравнить, насколько наша сеть стала быстрее по сравнению с оригинальной"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yA4m3w2cRhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17508e3a-e826-42c4-f626-5f44f4822b6b"
      },
      "source": [
        "%%timeit -r5\n",
        "\n",
        "with single_thread():\n",
        "    evaluate(resnet, test_loader, device='cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:0.925% \n",
            "Test accuracy:0.925% \n",
            "Test accuracy:0.925% \n",
            "Test accuracy:0.925% \n",
            "Test accuracy:0.925% \n",
            "Test accuracy:0.925% \n",
            "1 loop, best of 5: 3min 52s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cEgrDjwi5Sf"
      },
      "source": [
        "## Квантизация в процессе обучения\n",
        "\n",
        "Этот метод заключается в том, что квантование происходит на каждом шаге градиентного спуска. С QAT (Quantization-aware training) все веса и активации «поддельно квантуются» во время как прямого, так и обратного проходов обучения: то есть числа с плавающей точкой округляются до имитации значений int8, но все вычисления по-прежнему выполняются во float32 представлении. Таким образом, все корректировки веса во время обучения производятся с учетом того факта, что модель в конечном итоге будет квантована; поэтому после квантования этот метод обычно дает более высокую точность, чем динамическое квантование или статическое квантование после обучения.\n",
        "\n",
        "Общий рабочий процесс для фактического выполнения QAT очень похож на предыдущий:\n",
        "\n",
        "Мы можем использовать ту же модель, что и раньше: для обучения с учетом квантования не требуется дополнительной подготовки.\n",
        "Нам нужно использовать qconfig, указывающий, какой тип фальшивого квантования должен быть вставлен после весов и активаций, вместо указания модулей наблюдателей (Histogram observers).\n",
        "\n",
        "Добавляем конфигурацию, после чего подготавливаем модель для обучения с квантованием\n",
        "\n",
        "Модель внутри себя автоматически будет обновлять веса с учетом квантования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocjexGywcon8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a871412-bd9f-4857-a41c-4b74677522b2"
      },
      "source": [
        "qa_resnet = ResNet()\n",
        "qa_resnet.to(DEVICE)\n",
        "qa_resnet.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
        "torch.quantization.prepare_qat(qa_resnet, inplace=True)\n",
        "torch.manual_seed(SEED)\n",
        "fit(qa_resnet, train_loader, epoch_number=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:123: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0 [0/60000 (0%)]\tLoss: 2.343018\t Accuracy:6.250%\n",
            "Epoch : 0 [16000/60000 (27%)]\tLoss: 0.299412\t Accuracy:76.659%\n",
            "Epoch : 0 [32000/60000 (53%)]\tLoss: 0.466928\t Accuracy:80.975%\n",
            "Epoch : 0 [48000/60000 (80%)]\tLoss: 0.425663\t Accuracy:83.405%\n",
            "Epoch : 1 [0/60000 (0%)]\tLoss: 0.144397\t Accuracy:96.875%\n",
            "Epoch : 1 [16000/60000 (27%)]\tLoss: 0.345503\t Accuracy:90.525%\n",
            "Epoch : 1 [32000/60000 (53%)]\tLoss: 0.087875\t Accuracy:90.325%\n",
            "Epoch : 1 [48000/60000 (80%)]\tLoss: 0.156576\t Accuracy:90.417%\n",
            "Epoch : 2 [0/60000 (0%)]\tLoss: 0.311665\t Accuracy:87.500%\n",
            "Epoch : 2 [16000/60000 (27%)]\tLoss: 0.117227\t Accuracy:92.072%\n",
            "Epoch : 2 [32000/60000 (53%)]\tLoss: 0.214537\t Accuracy:91.899%\n",
            "Epoch : 2 [48000/60000 (80%)]\tLoss: 0.109145\t Accuracy:92.009%\n",
            "Epoch : 3 [0/60000 (0%)]\tLoss: 0.104612\t Accuracy:96.875%\n",
            "Epoch : 3 [16000/60000 (27%)]\tLoss: 0.080911\t Accuracy:93.438%\n",
            "Epoch : 3 [32000/60000 (53%)]\tLoss: 0.292502\t Accuracy:93.316%\n",
            "Epoch : 3 [48000/60000 (80%)]\tLoss: 0.255406\t Accuracy:93.294%\n",
            "Epoch : 4 [0/60000 (0%)]\tLoss: 0.063489\t Accuracy:96.875%\n",
            "Epoch : 4 [16000/60000 (27%)]\tLoss: 0.085357\t Accuracy:94.573%\n",
            "Epoch : 4 [32000/60000 (53%)]\tLoss: 0.159760\t Accuracy:94.527%\n",
            "Epoch : 4 [48000/60000 (80%)]\tLoss: 0.089332\t Accuracy:94.418%\n",
            "Epoch : 5 [0/60000 (0%)]\tLoss: 0.159891\t Accuracy:93.750%\n",
            "Epoch : 5 [16000/60000 (27%)]\tLoss: 0.082375\t Accuracy:95.571%\n",
            "Epoch : 5 [32000/60000 (53%)]\tLoss: 0.034472\t Accuracy:95.345%\n",
            "Epoch : 5 [48000/60000 (80%)]\tLoss: 0.416553\t Accuracy:95.295%\n",
            "Epoch : 6 [0/60000 (0%)]\tLoss: 0.049946\t Accuracy:100.000%\n",
            "Epoch : 6 [16000/60000 (27%)]\tLoss: 0.057656\t Accuracy:96.794%\n",
            "Epoch : 6 [32000/60000 (53%)]\tLoss: 0.187858\t Accuracy:96.479%\n",
            "Epoch : 6 [48000/60000 (80%)]\tLoss: 0.126579\t Accuracy:96.400%\n",
            "Epoch : 7 [0/60000 (0%)]\tLoss: 0.018122\t Accuracy:100.000%\n",
            "Epoch : 7 [16000/60000 (27%)]\tLoss: 0.134156\t Accuracy:97.648%\n",
            "Epoch : 7 [32000/60000 (53%)]\tLoss: 0.135824\t Accuracy:97.540%\n",
            "Epoch : 7 [48000/60000 (80%)]\tLoss: 0.059220\t Accuracy:97.423%\n",
            "Epoch : 8 [0/60000 (0%)]\tLoss: 0.023615\t Accuracy:100.000%\n",
            "Epoch : 8 [16000/60000 (27%)]\tLoss: 0.005467\t Accuracy:98.397%\n",
            "Epoch : 8 [32000/60000 (53%)]\tLoss: 0.046253\t Accuracy:98.155%\n",
            "Epoch : 8 [48000/60000 (80%)]\tLoss: 0.088095\t Accuracy:97.970%\n",
            "Epoch : 9 [0/60000 (0%)]\tLoss: 0.011149\t Accuracy:100.000%\n",
            "Epoch : 9 [16000/60000 (27%)]\tLoss: 0.035498\t Accuracy:98.771%\n",
            "Epoch : 9 [32000/60000 (53%)]\tLoss: 0.002558\t Accuracy:98.751%\n",
            "Epoch : 9 [48000/60000 (80%)]\tLoss: 0.118377\t Accuracy:98.630%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reDwSunKiqTj"
      },
      "source": [
        "После обучения с квантованием, фиксируем квантованные веса и параметры. Таким образом получаем финальную сеть для последующего использования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU2N0YMadUI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01a8c57a-24e9-4d17-c8bf-f8c96dda2b45"
      },
      "source": [
        "qa_resnet.to('cpu')\n",
        "quantized_model = torch.quantization.convert(qa_resnet, inplace=False)\n",
        "evaluate(quantized_model, test_loader, device='cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:0.925% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGByMuSxj8GM"
      },
      "source": [
        "Видим, что нам удалось все также уменьшить вес сети, как и при статической квантизации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy-k9kMkdbfJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "63720e7a-2cfa-425e-eddf-4052f3e9127a"
      },
      "source": [
        "calc_size(quantized_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'11128.655 KB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ4qSWlXkSI2"
      },
      "source": [
        "Таким образом происходит применение алгоритмов квантизации на практике. Как видно из примера, удалось эффективно перевести веса модели ResNet18 в int8 представление, тем самым уменьшить требуемую память для хранения сети и значительно ускорить пропускную способность на процессоре."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32zLmaPrd4E-",
        "outputId": "9fe9de61-cc0b-4e63-c74d-a1a492d665c4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp \"drive/My Drive/Colab Notebooks/quantization.ipynb\" ./\n",
        "\n",
        "!jupyter nbconvert --to latex quantization.ipynb\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[NbConvertApp] Converting notebook quantization.ipynb to latex\n",
            "[NbConvertApp] Writing 79478 bytes to quantization.tex\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDbO89Mfd5cm"
      },
      "source": [
        "!cp quantization.tex \"drive/My Drive/Colab Notebooks/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3IjlzdwfDLb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}